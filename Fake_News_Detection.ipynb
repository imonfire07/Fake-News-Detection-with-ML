{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensorflow as tf\n",
    "frimport tom tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are just variables for using while tokenization,setting data usage limits and other purposes\n",
    "training_size = 15000\n",
    "embedding_dim = 16\n",
    "vocab_size = 10000\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "padding_type='post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'author', 'text', 'label'], dtype='object')\n",
      "   id                                              title              author  \\\n",
      "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
      "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
      "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
      "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
      "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
      "\n",
      "                                                text  label  \n",
      "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
      "1  Ever get the feeling your life circles the rou...      0  \n",
      "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
      "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
      "4  Print \\nAn Iranian woman has been sentenced to...      1  \n",
      "id        0\n",
      "title     0\n",
      "author    0\n",
      "text      0\n",
      "label     0\n",
      "dtype: int64\n",
      "(18285, 5)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"train.csv\")\n",
    "#reading data from a csv file dataset\n",
    "print(df.columns)#shows all the columnnames of the dataset \n",
    "print(df.head(5))#shows data of the first five rows\n",
    "df.dropna(inplace=True)#removes the missing value rows\n",
    "print(df.isnull().sum())#shows missing value counts of each attribute\n",
    "print(df.shape)#shows the dimensions of the dataset\n",
    "\n",
    "\n",
    "text= []\n",
    "label = []\n",
    "\n",
    "#storing the title and label values in the empty lists\n",
    "ti= df.loc[:,'text']\n",
    "text= ti.values.tolist()\n",
    "for i in range(len(text)):\n",
    "    x=isinstance(text[i],str)\n",
    "    if x == False:\n",
    "        text[i] = str(text[i])\n",
    "        \n",
    "\n",
    "lbl= df.loc[:,'label']\n",
    "label= lbl.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separates the training and testing titles for validation\n",
    "training_title = text[0:training_size]\n",
    "testing_title = text[training_size:]\n",
    "\n",
    "#separates the training and testing labels for validation\n",
    "training_label = label[0:training_size]\n",
    "testing_label = label[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section adds tokens to every word found after fitting on the training sentences\n",
    "tokenizer = Tokenizer(num_words=vocab_size,oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(training_title)\n",
    "\n",
    "# holds the index value of each word found on in the training data sets\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# text to sequences is a procedure to convert the words of each sentences into sequence represented by a list\n",
    "# padding is a procedure of adding zeros to empty spaces just to maintain a constant length of every sentence\n",
    "training_sequences = tokenizer.texts_to_sequences(training_title)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_title)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "# print(training_sequences)\n",
    "# print(training_padded)\n",
    "\n",
    "#storing the padded_titles and labels in arrays\n",
    "training_padded_title = np.array(training_padded)\n",
    "testing_padded_title = np.array(testing_padded)\n",
    "\n",
    "training_label = np.array(training_label)\n",
    "testing_label = np.array(testing_label)\n",
    "\n",
    "# model creation code is below. (Sequential) allows us to create multiple neural networks. (Embedding) is a process of graphing the sentiment of each word, epoch by epoch, on a numberline(vector) and then applying multiple vectors for multiple words. \n",
    "# (AveragePooling) provides the resultant vector sum value by a binary sentiment like good or bad.\n",
    "# these values are then fed to a deep neural network\n",
    "# RELU stand for rectified linear unit which is simply an if else condition which returns a value if it is (>) greater than 0 or returns 0.\n",
    "# 24 and 1 are the number of neurons on a neural network\n",
    "# the activation function specifies what is the work of each neural network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 160,433\n",
      "Trainable params: 160,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15000 samples, validate on 3285 samples\n",
      "Epoch 1/50\n",
      "15000/15000 - 3s - loss: 0.4416 - accuracy: 0.7989 - val_loss: 0.2282 - val_accuracy: 0.9205\n",
      "Epoch 2/50\n",
      "15000/15000 - 2s - loss: 0.1532 - accuracy: 0.9449 - val_loss: 0.1595 - val_accuracy: 0.9382\n",
      "Epoch 3/50\n",
      "15000/15000 - 2s - loss: 0.0899 - accuracy: 0.9712 - val_loss: 0.1485 - val_accuracy: 0.9434\n",
      "Epoch 4/50\n",
      "15000/15000 - 2s - loss: 0.0564 - accuracy: 0.9841 - val_loss: 0.1543 - val_accuracy: 0.9428\n",
      "Epoch 5/50\n",
      "15000/15000 - 2s - loss: 0.0348 - accuracy: 0.9927 - val_loss: 0.1687 - val_accuracy: 0.9409\n",
      "Epoch 6/50\n",
      "15000/15000 - 2s - loss: 0.0199 - accuracy: 0.9964 - val_loss: 0.1819 - val_accuracy: 0.9400\n",
      "Epoch 7/50\n",
      "15000/15000 - 2s - loss: 0.0110 - accuracy: 0.9989 - val_loss: 0.1996 - val_accuracy: 0.9394\n",
      "Epoch 8/50\n",
      "15000/15000 - 2s - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.2165 - val_accuracy: 0.9367\n",
      "Epoch 9/50\n",
      "15000/15000 - 3s - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.2377 - val_accuracy: 0.9379\n",
      "Epoch 10/50\n",
      "15000/15000 - 2s - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.2491 - val_accuracy: 0.9379\n",
      "Epoch 11/50\n",
      "15000/15000 - 2s - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.2641 - val_accuracy: 0.9379\n",
      "Epoch 12/50\n",
      "15000/15000 - 2s - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.2753 - val_accuracy: 0.9367\n",
      "Epoch 13/50\n",
      "15000/15000 - 2s - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.2835 - val_accuracy: 0.9346\n",
      "Epoch 14/50\n",
      "15000/15000 - 2s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.2960 - val_accuracy: 0.9370\n",
      "Epoch 15/50\n",
      "15000/15000 - 2s - loss: 9.1520e-04 - accuracy: 0.9999 - val_loss: 0.3058 - val_accuracy: 0.9370\n",
      "Epoch 16/50\n",
      "15000/15000 - 2s - loss: 9.2203e-04 - accuracy: 0.9998 - val_loss: 0.3176 - val_accuracy: 0.9379\n",
      "Epoch 17/50\n",
      "15000/15000 - 2s - loss: 8.2203e-04 - accuracy: 0.9999 - val_loss: 0.3245 - val_accuracy: 0.9379\n",
      "Epoch 18/50\n",
      "15000/15000 - 2s - loss: 7.6315e-04 - accuracy: 0.9999 - val_loss: 0.3309 - val_accuracy: 0.9370\n",
      "Epoch 19/50\n",
      "15000/15000 - 2s - loss: 7.5847e-04 - accuracy: 0.9999 - val_loss: 0.3457 - val_accuracy: 0.9352\n",
      "Epoch 20/50\n",
      "15000/15000 - 2s - loss: 7.1340e-04 - accuracy: 0.9999 - val_loss: 0.3541 - val_accuracy: 0.9358\n",
      "Epoch 21/50\n",
      "15000/15000 - 2s - loss: 7.3457e-04 - accuracy: 0.9999 - val_loss: 0.3643 - val_accuracy: 0.9324\n",
      "Epoch 22/50\n",
      "15000/15000 - 2s - loss: 7.3056e-04 - accuracy: 0.9999 - val_loss: 0.3668 - val_accuracy: 0.9355\n",
      "Epoch 23/50\n",
      "15000/15000 - 2s - loss: 6.6081e-04 - accuracy: 0.9999 - val_loss: 0.3750 - val_accuracy: 0.9336\n",
      "Epoch 24/50\n",
      "15000/15000 - 2s - loss: 6.2797e-04 - accuracy: 0.9999 - val_loss: 0.3842 - val_accuracy: 0.9333\n",
      "Epoch 25/50\n",
      "15000/15000 - 2s - loss: 6.0044e-04 - accuracy: 0.9999 - val_loss: 0.3934 - val_accuracy: 0.9324\n",
      "Epoch 26/50\n",
      "15000/15000 - 2s - loss: 5.5374e-04 - accuracy: 0.9999 - val_loss: 0.4010 - val_accuracy: 0.9321\n",
      "Epoch 27/50\n",
      "15000/15000 - 2s - loss: 5.1440e-04 - accuracy: 0.9999 - val_loss: 0.4124 - val_accuracy: 0.9333\n",
      "Epoch 28/50\n",
      "15000/15000 - 2s - loss: 5.7884e-04 - accuracy: 0.9999 - val_loss: 0.4191 - val_accuracy: 0.9312\n",
      "Epoch 29/50\n",
      "15000/15000 - 2s - loss: 5.7242e-04 - accuracy: 0.9999 - val_loss: 0.4269 - val_accuracy: 0.9300\n",
      "Epoch 30/50\n",
      "15000/15000 - 2s - loss: 6.4332e-04 - accuracy: 0.9999 - val_loss: 0.4366 - val_accuracy: 0.9288\n",
      "Epoch 31/50\n",
      "15000/15000 - 2s - loss: 4.3900e-04 - accuracy: 0.9999 - val_loss: 0.4537 - val_accuracy: 0.9282\n",
      "Epoch 32/50\n",
      "15000/15000 - 2s - loss: 4.1801e-04 - accuracy: 0.9999 - val_loss: 0.4611 - val_accuracy: 0.9275\n",
      "Epoch 33/50\n",
      "15000/15000 - 2s - loss: 5.4661e-04 - accuracy: 0.9999 - val_loss: 0.4618 - val_accuracy: 0.9272\n",
      "Epoch 34/50\n",
      "15000/15000 - 2s - loss: 4.2986e-04 - accuracy: 0.9999 - val_loss: 0.4728 - val_accuracy: 0.9269\n",
      "Epoch 35/50\n",
      "15000/15000 - 2s - loss: 4.4861e-04 - accuracy: 0.9999 - val_loss: 0.4752 - val_accuracy: 0.9272\n",
      "Epoch 36/50\n",
      "15000/15000 - 2s - loss: 3.6141e-04 - accuracy: 0.9999 - val_loss: 0.4770 - val_accuracy: 0.9275\n",
      "Epoch 37/50\n",
      "15000/15000 - 2s - loss: 5.0736e-04 - accuracy: 0.9999 - val_loss: 0.5045 - val_accuracy: 0.9282\n",
      "Epoch 38/50\n",
      "15000/15000 - 2s - loss: 5.3731e-04 - accuracy: 0.9999 - val_loss: 0.5067 - val_accuracy: 0.9282\n",
      "Epoch 39/50\n",
      "15000/15000 - 2s - loss: 3.6475e-04 - accuracy: 0.9999 - val_loss: 0.5186 - val_accuracy: 0.9272\n",
      "Epoch 40/50\n",
      "15000/15000 - 2s - loss: 3.3366e-04 - accuracy: 0.9999 - val_loss: 0.5234 - val_accuracy: 0.9285\n",
      "Epoch 41/50\n",
      "15000/15000 - 2s - loss: 4.5269e-04 - accuracy: 0.9999 - val_loss: 0.5527 - val_accuracy: 0.9257\n",
      "Epoch 42/50\n",
      "15000/15000 - 2s - loss: 4.3777e-04 - accuracy: 0.9999 - val_loss: 0.5465 - val_accuracy: 0.9260\n",
      "Epoch 43/50\n",
      "15000/15000 - 2s - loss: 3.7902e-04 - accuracy: 0.9999 - val_loss: 0.5698 - val_accuracy: 0.9263\n",
      "Epoch 44/50\n",
      "15000/15000 - 2s - loss: 3.5863e-04 - accuracy: 0.9999 - val_loss: 0.5909 - val_accuracy: 0.9248\n",
      "Epoch 45/50\n",
      "15000/15000 - 2s - loss: 2.8056e-04 - accuracy: 0.9999 - val_loss: 0.5888 - val_accuracy: 0.9239\n",
      "Epoch 46/50\n",
      "15000/15000 - 2s - loss: 2.7859e-04 - accuracy: 0.9999 - val_loss: 0.5910 - val_accuracy: 0.9248\n",
      "Epoch 47/50\n",
      "15000/15000 - 2s - loss: 3.5196e-04 - accuracy: 0.9999 - val_loss: 0.5906 - val_accuracy: 0.9260\n",
      "Epoch 48/50\n",
      "15000/15000 - 2s - loss: 2.7700e-04 - accuracy: 0.9999 - val_loss: 0.6026 - val_accuracy: 0.9251\n",
      "Epoch 49/50\n",
      "15000/15000 - 3s - loss: 2.9301e-04 - accuracy: 0.9999 - val_loss: 0.6092 - val_accuracy: 0.9254\n",
      "Epoch 50/50\n",
      "15000/15000 - 3s - loss: 4.2817e-04 - accuracy: 0.9999 - val_loss: 0.6136 - val_accuracy: 0.9266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a88218988>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: 'Loss' provides the calculation of loss prediction value and 'optimizer' is the error rectification procedure through their respective functions \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "num_epochs = 50\n",
    "\n",
    "# training of the model is done using the model.fit\n",
    "title_history = model.fit(training_padded_title, training_label, epochs=num_epochs, validation_data=(testing_padded_title,testing_label), verbose=2)\n",
    "title_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of news to be validated\n",
      "2\n",
      "Enter news to be validated\n",
      "New york in in India\n",
      "Enter news to be validated\n",
      "Sun rises in west\n",
      "['New york in in India', 'Sun rises in west']\n",
      "[[0.9987527 ]\n",
      " [0.99460727]]\n",
      "[0.9987527]\n",
      "New york in in India IS A FAKE NEWS\n",
      "[0.99460727]\n",
      "Sun rises in west IS A FAKE NEWS\n"
     ]
    }
   ],
   "source": [
    "news = []\n",
    "print('Enter number of news to be validated' )\n",
    "#taking the number of news to be validate as an integer input from the user\n",
    "news_number= int(input())\n",
    "for i in range(news_number):\n",
    "    print('Enter news to be validated')\n",
    "    #taking news input as string from the user\n",
    "    n = input()\n",
    "    news.append(n)\n",
    "print(news)\n",
    "\n",
    "#tokenization of the input news\n",
    "sequences = tokenizer.texts_to_sequences(news)\n",
    "#padding of the tokenized sequences\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "#predicting a value for evaluation\n",
    "predict_value = model.predict(padded)\n",
    "print(predict_value)\n",
    "for i in range(len(news)):\n",
    "    print(predict_value[i])\n",
    "    if predict_value[i] > 0.9996:\n",
    "        print(news[i]+' IS A TRUE NEWS')\n",
    "    else:\n",
    "        print(news[i]+' IS A FAKE NEWS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
